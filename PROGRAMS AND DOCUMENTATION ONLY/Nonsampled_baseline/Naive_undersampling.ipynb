{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Fw8wt4Q3nN5"
   },
   "source": [
    "#Author: Srikaran Elakurthy\n",
    "\n",
    "#Description \n",
    "\n",
    "Importing the train set and test set for using in Naive Bayes model.\n",
    "Implementing the Multinomial Naive bayes classification on the above dataset.\n",
    "Performing Cross validation with kfolds=5 and extract average accuracy\n",
    "Training the naive bayes model on whole train data and testing it\n",
    "storing the results into files\n",
    "\n",
    ">*Detailed description is written for many parts of the code below. Please read through for the same.\n",
    "\n",
    "# Command to Run \n",
    "\n",
    "> Open the ipynb notebook in Jupyter Lab and go to the menu bar on the top, click on 'Run' and from the dropdown select the 'Run All' option to run all the cells in the notebook.\n",
    "\n",
    "\n",
    "#Input and Output\n",
    "\n",
    "Input files: \n",
    ">nonsampling_train.csv - It consists of the preprocessed and unsampled  version of lyrics from the dataset. It is only for training the models.\n",
    "\n",
    ">nonsampling_test.csv - It consists of the preprocessed and unsampled  version of lyrics from the dataset. It is only for testing the models.\n",
    "\n",
    "Ouputs: \n",
    ">finalmodelNaiveBayes_undersampled.pkl - Trained Naive Bayes model on the whole train set.\n",
    "\n",
    ">finalNaiveundersamp_results.txt - Cross validation Results of the trained model on the non sampled data set.\n",
    "\n",
    ">NaiveBayes.pkl - Models generated during the K-Fold cross validation\n",
    "\n",
    ">Naiveundersamp_results.txt - Writing the cross validation metrics to the txt file.\n",
    "\n",
    "Input<- The inputs to the code are nonsampling_train.csv and nonsampling_test.csv\n",
    "Output<-\n",
    " report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Rock       0.00      0.00      0.00      2863\n",
    "     Country       0.00      0.00      0.00      1407\n",
    "     Hip-Hop       0.00      0.00      0.00       356\n",
    "         Pop       0.93      0.24      0.38      4618\n",
    "        Jazz       0.00      0.00      0.00       587\n",
    "         R&B       0.00      0.00      0.00      1449\n",
    "       Metal       1.00      0.00      0.01      4285\n",
    "      Electronic   0.00      0.00      0.00       764\n",
    "       Other       0.81      0.00      0.01      6985\n",
    "        Folk       0.00      0.00      0.00       651\n",
    "       Indie       0.47      1.00      0.64     20165\n",
    "\n",
    "    accuracy                            0.48     44130\n",
    "    macro avg       0.29      0.11      0.09     44130\n",
    "    weighted avg    0.54      0.48      0.33     44130\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onPqDiPf4Mkd"
   },
   "source": [
    "Importing th required packages and train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L-nYB8_83h7u",
    "outputId": "2b6433f0-eebe-4e7d-9d9e-4ee8f8244064"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from langdetect import detect\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import emoji\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.preprocessing import Normalizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import classification_report\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "traindf=pd.read_csv(\"nonsampling_train.csv\")\n",
    "testdf=pd.read_csv(\"nonsampling_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bGV6N2B53h72",
    "outputId": "80d55ded-bf93-4571-ab0b-5d295fd8052f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173586</td>\n",
       "      <td>i wait for the pain it alway come again and i ...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192873</td>\n",
       "      <td>as i hear the mock bird i rememb the word when...</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196702</td>\n",
       "      <td>gab yeah yeah x lateef blackalici lateef the t...</td>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34320</td>\n",
       "      <td>well the sky broke in two i found you danc alo...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77537</td>\n",
       "      <td>when madam pompadour wa on a ballroom floor sa...</td>\n",
       "      <td>Jazz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             lyrics    genre\n",
       "0      173586  i wait for the pain it alway come again and i ...     Rock\n",
       "1      192873  as i hear the mock bird i rememb the word when...  Country\n",
       "2      196702  gab yeah yeah x lateef blackalici lateef the t...  Hip-Hop\n",
       "3       34320  well the sky broke in two i found you danc alo...      Pop\n",
       "4       77537  when madam pompadour wa on a ballroom floor sa...     Jazz"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUD_vn2b4X9d"
   },
   "source": [
    "Dropping the unnamed column which has been created when we are importing the csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZgX72VD3h79"
   },
   "outputs": [],
   "source": [
    "traindf.drop(traindf.columns[traindf.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "\n",
    "testdf.drop(testdf.columns[testdf.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2s65RvZ3h8B",
    "outputId": "25d0eb32-8003-4706-8def-8edf6bf605d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Rock', 'Country', 'Hip-Hop', 'Pop', 'Jazz', 'R&B', 'Metal',\n",
       "       'Electronic', 'Other', 'Folk', 'Indie'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.genre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKEGcqRx3h8F"
   },
   "outputs": [],
   "source": [
    "lyrics=traindf['lyrics']\n",
    "genre=traindf['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dY_uufLg4hzl"
   },
   "source": [
    "Performing cross validation with 5 splits and implementing tfidf vectorization inside the cross validation to avoid any data leakage.\n",
    "TFidf Vectorization will consider parameters stop_words= english specifying that it will be removing any english words and says to consider both unigrams and bigrams.\n",
    "We are taking Multinomial Naive bayes model specifying we are seeking a multi class problem and alpha =1 specifying smoothing is allowed. \n",
    "Storing the models in pickle files using joblib and results with actual and predicted values into a csv file.\n",
    "Storing the accuracy of every cross validation split into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddoHMmlW3h8I",
    "outputId": "3ce70e9b-b2b9-4a6d-9494-ea63618b2ad1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 33443  33455  33468 ... 176517 176518 176519]\n",
      "[    0     1     2 ... 36103 36246 36370]\n",
      "tfidf1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4803138454566055\n",
      "[     0      1      2 ... 176517 176518 176519]\n",
      "[33443 33455 33468 ... 71608 71687 71705]\n",
      "tfidf2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4797190120099705\n",
      "[     0      1      2 ... 176517 176518 176519]\n",
      "[ 67218  67221  67329 ... 107216 107234 107296]\n",
      "tfidf3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47929413097665985\n",
      "[     0      1      2 ... 176517 176518 176519]\n",
      "[102550 102551 102738 ... 145107 145206 145391]\n",
      "tfidf4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4795490595966463\n",
      "[     0      1      2 ... 145107 145206 145391]\n",
      "[139006 139414 139416 ... 176517 176518 176519]\n",
      "tfidf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4803421708588262\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "i=0\n",
    "logirep=[]\n",
    "logiscore=[]\n",
    "for train_index, test_index in skf.split(lyrics, genre):\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    x_train1, x_test1 = lyrics.iloc[train_index], lyrics.iloc[test_index]\n",
    "    y_train, y_test = genre.iloc[train_index], genre.iloc[test_index]\n",
    "    i=i+1\n",
    "    tfidf = TfidfVectorizer(stop_words=\"english\",ngram_range=(1,2))\n",
    "    x_train = tfidf.fit_transform(x_train1)\n",
    "    x_test = tfidf.transform(x_test1)\n",
    "    print(\"tfidf\"+str(i))\n",
    "    \n",
    "    clf = MultinomialNB(alpha=1.0)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    joblib.dump(clf, 'NaiveBayes'+str(i)+'.pkl')\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    rep=classification_report(y_test, y_pred, target_names=traindf.genre.unique())\n",
    "    logirep.append(rep)\n",
    "    dat={'Actual':y_test,'pred':y_pred}\n",
    "    resdf=pd.DataFrame(dat)\n",
    "    resdf.to_csv('resNaivebayes'+str(i)+'.csv')\n",
    "    logiscore.append(score)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TLwsvSnt44Aa"
   },
   "source": [
    "Creating a file to write our classification report for our 5 results of Cross validation models and computing the average accuracy and writing them into the file.\n",
    "The classification report is computed by using the results csv files containing the actual and predicted values of ech split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JdjXSqW3h8K"
   },
   "outputs": [],
   "source": [
    "f=open(\"Naiveundersamp_results.txt\",\"a\")\n",
    "\n",
    "for i in range(1,6):\n",
    "    f.write(\"\\n report\"+str(i)+\":\\n\")\n",
    "    dfr=pd.read_csv(\"resNaivebayes\"+str(i)+\".csv\")\n",
    "    dfr.drop(dfr.columns[dfr.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "    f.write(classification_report(dfr.Actual, dfr.pred, target_names=traindf.genre.unique()))\n",
    "f.write(\"\\nThe average score for this model is\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7HB6k-ds48Ki"
   },
   "source": [
    "Declaring the naive bayes model with alpha =1 specifying smoothing is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3kjMDt8R3h8M"
   },
   "outputs": [],
   "source": [
    "finalmod = MultinomialNB(alpha=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AB0BTx1U5Q4o"
   },
   "source": [
    "Perform tfidf vectorization to extraxt tfidf matrix on whole training data and use the fitted vectorizer to transform the test data to tfidf matrix.\n",
    "\n",
    "Tfidf matrix considers:\n",
    "*   Removing stop words\n",
    "*   Considering both unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_iePR0E3h8N"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\",ngram_range=(1,2))\n",
    "trainvec = tfidf.fit_transform(traindf['lyrics'])\n",
    "testvec = tfidf.transform(testdf['lyrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9F7qk1pL5Av9"
   },
   "source": [
    "Fitting the model with train tfidf matrix and train target variable(genre's)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNBQXcqm3h8P",
    "outputId": "2c10eb6c-68ad-4074-c01a-0eff80d2b760"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalmod.fit(trainvec, traindf['genre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gy_Bppo_5XJe"
   },
   "source": [
    "Storing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O38jADw23h8R",
    "outputId": "cf44de04-7665-4fb5-b545-5476bbaa2f92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finalmodelNaiveBayes_undersampled.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(finalmod, 'finalmodelNaiveBayes_undersampled.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PPvfVPP5ZJc"
   },
   "source": [
    "Predicting the test data using test tfidf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVFiXgrA3h8T"
   },
   "outputs": [],
   "source": [
    "y_pred = finalmod.predict(testvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSUQWXrc5eCi"
   },
   "source": [
    "Computing the classification report and writing the results into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fk_1ASRm3h8U",
    "outputId": "7fdd209e-bcb4-4169-e0f0-c045c9eaa465"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "f=open(\"finalNaiveundersamp_results.txt\",\"a\")\n",
    "f.write(\"\\n report:\\n\")\n",
    "f.write(classification_report(testdf['genre'], y_pred, target_names=traindf.genre.unique()))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Naive_undersampling.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
