{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0URTEgNwkPKe"
   },
   "source": [
    "#Author: Srikaran Elakurthy\n",
    "\n",
    "#Description\n",
    "*   Import the processed cleaned lyrics dataset and divide into train set and test set and store them into csv files for further use of them in Naive Bayes model.\n",
    "*   Implementing the logistic multi class classification on the above dataset.\n",
    "\n",
    "\n",
    "*   Performing Cross validation with kfolds =5 and extract  average accuracy \n",
    "*   Implementing class weighted approach by using class_weighted as balanced feature determining the model to give high priority to minority classes and low priority to majority classes.\n",
    "\n",
    "Detailed description is provided all along the program. Please read through the comments for a detailed picture.\n",
    "\n",
    "# Command to Run \n",
    "\n",
    "> Open the ipynb notebook in Jupyter Lab and go to the menu bar on the top, click on 'Run' and from the dropdown select the 'Run All' option to run all the cells in the notebook.\n",
    "\n",
    "# Inputs and Outputs\n",
    "\n",
    "Inputs:\n",
    "\n",
    "> processed_lyics.csv - It contains the preprocessed lyrics generated by the data pre-processing script.\n",
    "\n",
    "Ouputs: \n",
    "\n",
    ">finallogiundersamp_results_class_weighted.txt - It contains the Classification Report generated by the trained model over the test set.\n",
    "\n",
    "> reslogiclassweighted.csv - It contains the actual and predicted values of the test set stored into a csv.\n",
    "\n",
    "\n",
    "> *The inputs to the program must be in the same folder as the script.\n",
    "\n",
    "Input<- The input to the program is processed_lyics.csv\n",
    "Output<-\n",
    "report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "        Rock       0.60      0.26      0.37      2863\n",
    "     Country       0.86      0.03      0.06      1407\n",
    "         Pop       1.00      0.04      0.08       356\n",
    "       Metal       0.85      0.76      0.80      4618\n",
    "        Jazz       0.00      0.00      0.00       587\n",
    "         R&B       0.53      0.16      0.24      1449\n",
    "     Hip-Hop       0.74      0.56      0.64      4285\n",
    "     Electronic    0.21      0.01      0.01       764\n",
    "        Folk       0.52      0.32      0.40      6985\n",
    "       Indie       0.77      0.03      0.05       651\n",
    "       Other       0.59      0.90      0.71     20165\n",
    "\n",
    "    accuracy                           0.62     44130\n",
    "    macro avg       0.61      0.28      0.31     44130\n",
    "    weighted avg       0.62      0.62      0.57     44130"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAK2p1YDsmFz"
   },
   "source": [
    "Importing the necessary python packages and reading the preprocessed lyrics dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMEiRiKtRxPt",
    "outputId": "cf4b7514-0d5d-4a8b-a0cb-0c270da60896"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from langdetect import detect\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import emoji\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.preprocessing import Normalizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import classification_report\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "df=pd.read_csv(\"processed_lyics.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3Rgj-BMSOe4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeGIPfXnRxP0",
    "outputId": "77f9400c-c263-4329-c3ef-f42926e112d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>index</th>\n",
       "      <th>is_eng</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>oh babi how you do you know i m gonna cut righ...</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>playin everyth so easi it s like you seem so s...</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>if you search for tender it isn t hard to find...</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>oh oh oh i oh oh oh i vers if i wrote a book a...</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>parti the peopl the peopl the parti it s pop n...</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           artist genre  index  is_eng  \\\n",
       "0           0  beyonce-knowles   Pop      0     1.0   \n",
       "1           1  beyonce-knowles   Pop      1     1.0   \n",
       "2           2  beyonce-knowles   Pop      2     1.0   \n",
       "3           3  beyonce-knowles   Pop      3     1.0   \n",
       "4           4  beyonce-knowles   Pop      4     1.0   \n",
       "\n",
       "                                              lyrics             song  year  \n",
       "0  oh babi how you do you know i m gonna cut righ...        ego-remix  2009  \n",
       "1  playin everyth so easi it s like you seem so s...     then-tell-me  2009  \n",
       "2  if you search for tender it isn t hard to find...          honesty  2009  \n",
       "3  oh oh oh i oh oh oh i vers if i wrote a book a...  you-are-my-rock  2009  \n",
       "4  parti the peopl the peopl the parti it s pop n...    black-culture  2009  "
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttOuHAdMxLUz"
   },
   "source": [
    "Removing the unnamed column which we obtained when we are importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ex0J2fvERxP4"
   },
   "outputs": [],
   "source": [
    "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1zMx7uCxoLo"
   },
   "source": [
    "Divison of train and test dataset and storing into two dataframes with test size as 20% fo whole data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j7E4gK_SRxP7"
   },
   "outputs": [],
   "source": [
    "X=df['lyrics']\n",
    "Y=df['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKTC9vFaRxP9",
    "outputId": "d3abea2b-43df-4fef-d250-ccfe1d3967c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176520,) (176520,)\n",
      "(44130,) (44130,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(Xtrain.shape,Ytrain.shape)\n",
    "print(Xtest.shape,Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9BMdHPARxQA"
   },
   "outputs": [],
   "source": [
    "frame = { 'lyrics': Xtrain, 'genre': Ytrain } \n",
    "traindf = pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3g_UeCEhRxQB"
   },
   "outputs": [],
   "source": [
    "traindf.to_csv(\"nonsampling_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FLVPwBpJRxQC"
   },
   "outputs": [],
   "source": [
    "testdf.to_csv(\"nonsampling_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_jp7oLSRxQD"
   },
   "outputs": [],
   "source": [
    "frame = { 'lyrics': Xtest, 'genre': Ytest } \n",
    "  \n",
    "testdf = pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "urBaeopiRxQF"
   },
   "outputs": [],
   "source": [
    "lyrics=Xtrain\n",
    "genre=Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWqC_-jYRxQG",
    "outputId": "1e9d2579-d375-4226-d2f8-a82785e1dcb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173586       Rock\n",
       "192873    Country\n",
       "196702    Hip-Hop\n",
       "34320         Pop\n",
       "77537        Jazz\n",
       "           ...   \n",
       "119879        Pop\n",
       "103694       Rock\n",
       "131932        Pop\n",
       "146867       Rock\n",
       "121958       Rock\n",
       "Name: genre, Length: 176520, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2WYmaWHyRSS"
   },
   "source": [
    "Performing cross validation with 5 splits and implementing tfidf vectorization inside the cross validation to avoid any data leakage.\n",
    "\n",
    "\n",
    "\n",
    "*   TFidf Vectorization will consider parameters stop_words= english specifying that it will be removing any english words and says to consider both unigrams and bigrams.\n",
    "*   We are specifying the parameters on logistic model as multiclass as multinonial specifying we are seeking a multi class problem and optimization algorithm as 'sag'. Using sag so that the it is best for converging fastly on large datasets.\n",
    "\n",
    "\n",
    "*   Storing the models in pickle files using joblib  and results with actual and predicted values into a csv file.\n",
    "*   Storing the accuracy of every cross validation split into a list.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Oem6J6xRxQI",
    "outputId": "15b687cb-ebbd-410b-8188-724a8de637b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 33443  33455  33468 ... 176517 176518 176519]\n",
      "[    0     1     2 ... 36103 36246 36370]\n",
      "tfidf1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6131033310673012\n",
      "[     0      1      2 ... 176517 176518 176519]\n",
      "[33443 33455 33468 ... 71608 71687 71705]\n",
      "tfidf2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.612338545207342\n",
      "[     0      1      2 ... 176517 176518 176519]\n",
      "[ 67218  67221  67329 ... 107216 107234 107296]\n",
      "tfidf3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6135282121006118\n",
      "[     0      1      2 ... 176517 176518 176519]\n",
      "[102550 102551 102738 ... 145107 145206 145391]\n",
      "tfidf4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6150011330160888\n",
      "[     0      1      2 ... 145107 145206 145391]\n",
      "[139006 139414 139416 ... 176517 176518 176519]\n",
      "tfidf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.611941989576252\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=0)\n",
    "i=0\n",
    "logirep=[]\n",
    "logiscore=[]\n",
    "for train_index, test_index in skf.split(lyrics, genre):\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    x_train1, x_test1 = lyrics.iloc[train_index], lyrics.iloc[test_index]\n",
    "    y_train, y_test = genre.iloc[train_index], genre.iloc[test_index]\n",
    "    i=i+1\n",
    "    tfidf = TfidfVectorizer(stop_words=\"english\",ngram_range=(1,2))\n",
    "    x_train = tfidf.fit_transform(x_train1)\n",
    "    x_test = tfidf.transform(x_test1)\n",
    "    print(\"tfidf\"+str(i))\n",
    "    \n",
    "    clf = LogisticRegression(multi_class='multinomial',solver='sag')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    joblib.dump(clf, 'logi'+str(i)+'.pkl')\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    rep=classification_report(y_test, y_pred, target_names=df.genre.unique())\n",
    "    logirep.append(rep)\n",
    "    dat={'Actual':y_test,'pred':y_pred}\n",
    "    resdf=pd.DataFrame(dat)\n",
    "    resdf.to_csv('reslogi'+str(i)+'.csv')\n",
    "    logiscore.append(score)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EylPncj_0MoM"
   },
   "source": [
    "Creating a file to write our classification report for our 5 results of Cross validation models and computing the average accuracy and writing them into the file.\n",
    "\n",
    "The classification report is computed by using the results csv files containing the actual and predicted values of ech split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uh_NonyRxQJ",
    "outputId": "7632dd3f-57df-470f-c492-db37a1a0cb1c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "f=open(\"logiundersamp_results.txt\",\"a\")\n",
    "\n",
    "for i in range(1,6):\n",
    "    f.write(\"\\n report\"+str(i)+\":\\n\")\n",
    "    dfr=pd.read_csv(\"reslogi\"+str(i)+\".csv\")\n",
    "    dfr.drop(dfr.columns[dfr.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "    f.write(classification_report(dfr.Actual, dfr.pred, target_names=df.genre.unique()))\n",
    "f.write(\"\\nThe average score for this model is\")\n",
    "f.write(str(mean(logiscore)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UHFkivF1ABz"
   },
   "source": [
    "Declaring our logistic model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TRsNMpDORxQN"
   },
   "outputs": [],
   "source": [
    "finalmod = LogisticRegression(multi_class='multinomial',solver='sag')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d-amOaRF1Dnm"
   },
   "source": [
    "Perform tfidf vectorization to extraxt tfidf matrix on whole training data and use the fitted vectorizer to transform the test data to tfidf matrix.\n",
    "\n",
    "Tfidf matrix considers:\n",
    "*   Removing stop words\n",
    "*   Considering both unigrams and bigrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1XKLlb18RxQO"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\",ngram_range=(1,2))\n",
    "trainvec = tfidf.fit_transform(Xtrain)\n",
    "testvec = tfidf.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Rsf89Ga1eo2"
   },
   "source": [
    "Fitting the logistic model with the tfidf train matrix and train target variable(genre's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_i3Gc91WRxQP",
    "outputId": "f6812bc1-c241-4d85-e001-6fcfefeacbbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='sag', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalmod.fit(trainvec, Ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NntZAHG1ok9"
   },
   "source": [
    "Predicting the test data taking input as test tfidf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moqcWlPVRxQQ"
   },
   "outputs": [],
   "source": [
    "y_pred = finalmod.predict(testvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIoFk0tx1yuw"
   },
   "source": [
    "Computing the classification report and writing the results into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hU6nUZH1RxQR",
    "outputId": "07410770-b87e-4aac-cc91-9a18c29d0ede"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "f=open(\"finallogiundersamp_results.txt\",\"a\")\n",
    "f.write(\"\\n report:\\n\")\n",
    "f.write(classification_report(Ytest, y_pred, target_names=df.genre.unique()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0ZO3Gmr2H0N"
   },
   "source": [
    "Computing the class weights according to the bias nature of classes. This is performed by using 'balanced' as parameter. Specifying the importance to given to each class based on the frequency of each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HfVmxga1RxQZ"
   },
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(Ytrain),\n",
    "                                                 Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDU_eH4LRxQa",
    "outputId": "751f876c-fb95-43b3-febc-d4799e3c13a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.40889137,  2.86302814, 11.25334693,  0.87132935,  6.71996345,\n",
       "        2.718034  ,  0.93065434,  4.97744191,  0.57653491,  5.94343434,\n",
       "        0.19962026])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXETicnz2l5s"
   },
   "source": [
    "Fitting a logistic regression model with previous parameters and extra parameter class_weights='balanced' to give priority to low bias classes and less priority to high bias classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2z6fJHdyRxQd"
   },
   "outputs": [],
   "source": [
    "finalmod = LogisticRegression(multi_class='multinomial',solver='sag',class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkBbWd9828fg"
   },
   "source": [
    "Fitting the logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_TdLA7SjRxQe",
    "outputId": "7815673d-9138-4863-8ba3-2fd3eb960267"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
       "                   penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "                   verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalmod.fit(trainvec, Ytrain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcAWJySU3RDK"
   },
   "source": [
    "Predicting the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YZrcCZMRxQf"
   },
   "outputs": [],
   "source": [
    "y_pred = finalmod.predict(testvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWV9-NLE3Tlf"
   },
   "source": [
    "Computing the classification report and storing the results into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77kJq9ToRxQg"
   },
   "outputs": [],
   "source": [
    "f=open(\"finallogiundersamp_results_class_weighted.txt\",\"a\")\n",
    "f.write(\"\\n report:\\n\")\n",
    "f.write(classification_report(Ytest, y_pred, target_names=df.genre.unique()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NbaIrMC3Y5H"
   },
   "source": [
    "Storing the actual and predicted values into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80XA90qbRxQh"
   },
   "outputs": [],
   "source": [
    "dat={'Actual':Ytest,'pred':y_pred}\n",
    "resdf=pd.DataFrame(dat)\n",
    "resdf.to_csv('reslogiclassweighted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6QRUO-aHRxQi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LogisticRegression_NonSampling.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
